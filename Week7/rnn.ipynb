{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ9oEAn43Wnk"
      },
      "source": [
        "# **DIVE INTO CODE COURSE**\n",
        "## **Sprint Deep Learning - Convolution Neural Network 2D**\n",
        "**Student Name**: Doan Anh Tien<br>\n",
        "**Student ID**: 1852789<br>\n",
        "**Email**: tien.doan.g0pr0@hcmut.edu.vn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJt2HavErNQs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import random\n",
        "from math import log2\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkkuRv7or0BF"
      },
      "source": [
        "### **[Problem 1] Creating a 2-D convolutional layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Support class and functions**"
      ],
      "metadata": {
        "id": "9fTNse081DnN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQUszf2Hhxju"
      },
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "#         self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "        self._stop = int(np.ceil(X.shape[0]/self.batch_size))\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, Z3):\n",
        "\n",
        "    DELTA = 1e-7\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(y * np.log(Z3 + DELTA))/batch_size\n",
        "\n",
        "class SimpleInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        pass\n",
        "\n",
        "    def Wx(self, n_features, n_nodes):\n",
        "        w = np.zeros((n_features, n_nodes))\n",
        "        return w\n",
        "\n",
        "    def Wh(self, n_nodes):\n",
        "        w = np.zeros((n_nodes, n_nodes))\n",
        "        return w\n",
        "\n",
        "    def B(self, n_nodes):\n",
        "        b = np.zeros(n_nodes)\n",
        "        return b\n",
        "\n",
        "class Tanh:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.tanh(A)\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        return dZ * (1 - (np.tanh(self.A))**2)\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        X = X.T\n",
        "        y = np.exp(X) / np.sum(np.exp(X), axis=0)\n",
        "\n",
        "        return y.T\n",
        "\n",
        "    def backward(self, Z3, y):\n",
        "        batch_size = y.shape[0]\n",
        "        ret = (Z3 - y)/batch_size\n",
        "\n",
        "        self.loss = cross_entropy_error(y, Z3)\n",
        "\n",
        "        return ret\n",
        "\n",
        "\n",
        "class ReLU:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        self.x = X\n",
        "\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def backward(self, X):\n",
        "\n",
        "        return np.where(self.x > 0, X, 0)\n",
        "\n",
        "\n",
        "class XavierInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        _ = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "\n",
        "        sigma = 1.0 / np.sqrt(n_nodes1)\n",
        "        w = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return w\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "\n",
        "        b = np.random.randn(n_nodes2)\n",
        "        return b\n",
        "\n",
        "class HeInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        _ = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "\n",
        "        sigma = np.sqrt( 2.0 / n_nodes1)\n",
        "        w = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return w\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "\n",
        "        b = np.random.randn(n_nodes2)\n",
        "        return b    \n",
        "    \n",
        "    \n",
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "    \n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return"
      ],
      "metadata": {
        "id": "DhnL6tNZWfNQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-93XH-ZZoS5"
      },
      "source": [
        "**Fully Connected Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-n-C8-hqyW"
      },
      "source": [
        "class SimpleRNN:\n",
        "    \"\"\"\n",
        "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2 : int\n",
        "      Number of nodes in the later layer\n",
        "    initializer: object\n",
        "      Instance of initialization method\n",
        "    optimizer: object\n",
        "      Instance of optimization method\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features, n_nodes, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "        self.Wx = self.initializer.Wx(self.n_features, self.n_nodes)\n",
        "        self.Wh = self.initializer.Wh(self.n_nodes)\n",
        "\n",
        "        self.B = self.initializer.B(self.n_nodes)\n",
        "\n",
        "        # Number of states\n",
        "        self.h = None\n",
        "        self.x = None\n",
        "\n",
        "        self.dWx = None\n",
        "        self.dWb = None\n",
        "        self.dB = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        Wx = self.Wx\n",
        "        Wh = self.Wh\n",
        "        B = self.B\n",
        "\n",
        "        # The input x to the entire RNN will be passed in an array like (batch_size, n_sequences, n_features)\n",
        "        batch_size, n_sequences, n_features = X.shape\n",
        "        n_features, n_nodes = Wx.shape\n",
        "\n",
        "        h = np.empty((batch_size, n_sequences, n_nodes), dtype='f')\n",
        "\n",
        "        for seq in range(n_sequences):\n",
        "          x = X[:, seq, :]\n",
        "          h_prev = self.h\n",
        "\n",
        "          a = np.dot(x, Wx) + np.dot(h_prev, Wh) + B\n",
        "          h_next = np.tanh(a)\n",
        "\n",
        "          self.x = x\n",
        "          self.h = h_next\n",
        "          h[:, seq, :] = self.h\n",
        "\n",
        "        self.state = h\n",
        "        \n",
        "        return self.h\n",
        "\n",
        "    def backward(self, dA):\n",
        "\n",
        "        self = self.optimizer.update(self)\n",
        "\n",
        "        return None"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611_SR4mrzVm"
      },
      "source": [
        "class ScratchSimpleRNNClassifier():\n",
        "    \"\"\"\n",
        "    Convolution neural network classifier with configurable structure\n",
        "    Parameters\n",
        "    ----------\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, epoch, batch_size, n_features, n_nodes, lr, sigma=0.01, optimizer=SGD, activation=Tanh, initializer=SimpleInitializer, verbose=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch = epoch\n",
        "        self.lr = lr     \n",
        "        self.sigma = sigma\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "\n",
        "        self.RNN1 = SimpleRNN(self.n_features, self.n_nodes, self.initializer(self.sigma), self.optimizer(self.lr))\n",
        "        self.activation1 = self.activation()\n",
        "        self.RNN2 = SimpleRNN(self.n_features, self.n_nodes, self.initializer(self.sigma), self.optimizer(self.lr))\n",
        "        self.activation2 = self.activation()\n",
        "        self.RNN3 = SimpleRNN(self.n_features, self.n_nodes, self.initializer(self.sigma), self.optimizer(self.lr))\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        self.loss_list = []\n",
        "        self.acc_list = []\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "\n",
        "        Z3 = self.forward(X)\n",
        "        self.backward(X, y, Z3)\n",
        "\n",
        "        loss = self.activation3.loss\n",
        "\n",
        "        self.loss_list.append(loss)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        A1 = self.RNN1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.RNN2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.RNN3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "\n",
        "        return Z3\n",
        "\n",
        "    def backward(self, X, y, Z4):\n",
        "\n",
        "        dA3 = self.activation3.backward(Z4, y)\n",
        "        dZ2 = self.RNN3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.RNN2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.RNN1.backward(dA1)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        y_pred = self.forward(_X)\n",
        "\n",
        "        return y_pred.argmax(axis=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
      ],
      "metadata": {
        "id": "7DWhJVgH6_vt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = SimpleRNN(n_features=n_features, n_nodes=n_nodes, initializer=SimpleInitializer(0.01), optimizer=SGD)\n",
        "rnn.Wx = w_x\n",
        "rnn.Wh = w_h\n",
        "rnn.h = h\n",
        "rnn.B = b\n",
        "\n",
        "hs = rnn.forward(x)\n",
        "print('Activation output value:', hs)\n",
        "print('State:\\n', rnn.state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtST6G-d7Ce2",
        "outputId": "8ee6e9aa-014a-43bd-ee47-3def3eb0489d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation output value: [[0.79494228 0.81839002 0.83939649 0.85584174]]\n",
            "State:\n",
            " [[[0.76188797 0.76213956 0.762391   0.7625584 ]\n",
            "  [0.792209   0.8141834  0.8340491  0.84977716]\n",
            "  [0.79494226 0.81839    0.8393965  0.85584176]]]\n"
          ]
        }
      ]
    }
  ]
}