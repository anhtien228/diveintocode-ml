{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "treatise_reading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ9oEAn43Wnk"
      },
      "source": [
        "# **DIVE INTO CODE COURSE**\n",
        "## **Treatise reading**\n",
        "**Student Name**: Doan Anh Tien<br>\n",
        "**Student ID**: 1852789<br>\n",
        "**Email**: tien.doan.g0pr0@hcmut.edu.vn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please read the following papers and answer the questions. This is a representative study of object detection using CNN.\n",
        "\n",
        "\n",
        "[8] Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks.In: Advances in neural information processing systems. (2015 ) 91–99`\n",
        "\n",
        "https://arxiv.org/pdf/1506.01497.pdf"
      ],
      "metadata": {
        "id": "mnoqrhrE7DBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problem**"
      ],
      "metadata": {
        "id": "3K4jtd8M7G6d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR3PLEXruO64"
      },
      "source": [
        "**1. What kind of method exists in the field of object detection?**\n",
        "\n",
        "Main methods in the field of object detection: region proposal methods (e.g., Selective search, EdgeBoxes) and region-based convolutional neural networks (SPPnet, Fast R-CNN)\n",
        "\n",
        ">(Abstract) Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. It says \"Faster\", but what mechanism was used to make it faster?**\n",
        "\n",
        "The authors indicated the \"attention\" mechanism, in which they merge the Regional Proposal Network (RPN) and Fast R-CNN into a single network by sharing they convolutional features, and the RPN component will tell the unified network where to look.\n",
        "\n",
        "And the author also provide the information of how region-based and region proposal ultilize the CPU and GPU to accelerate their work. This lead to the fact that to make the proposal computation faster, they need to reimplement it for the GPU.\n",
        "\n",
        "> (Abstract) We further merge RPN and Fast R-CNN\n",
        "into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with\n",
        "“attention” mechanisms, the RPN component tells the unified network where to look.\n",
        "\n",
        "> (1. Introduction) One may note that fast region-based CNNs take\n",
        "advantage of GPUs, while the region proposal methods used in research are implemented on the CPU, making such runtime comparisons inequitable. An obvious way to accelerate proposal computation is to reimplement it for the GPU.\n"
      ],
      "metadata": {
        "id": "OeSHuGve_8bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How is the One-Stage method different from the Two-Stage method?**\n",
        "\n",
        "For One-Stage method\n",
        "* A pipeline with only class-specific detection\n",
        "* Region-wise features come from a sliding window of\n",
        "one aspect ratio over a scale pyramid\n",
        "\n",
        "\n",
        "For Two-Stage method\n",
        "* Consists of class-agnostic proposalsa and class-specific detection\n",
        "* Region-wise features come from square (3×3) sliding windows\n",
        "* The second stage is where the region-wise features are adaptively pooled\n",
        "\n",
        "> (4.1. Experiments on PASCAL VOC) One-Stage Detection vs. Two-Stage Proposal + Detection. The OverFeat paper [9] proposes a detection\n",
        "method that uses regressors and classifiers on sliding\n",
        "windows over convolutional feature maps. OverFeat\n",
        "is a one-stage, class-specific detection pipeline, and ours\n",
        "is a two-stage cascade consisting of class-agnostic proposals and class-specific detections. In OverFeat, the\n",
        "region-wise features come from a sliding window of\n",
        "one aspect ratio over a scale pyramid. These features\n",
        "are used to simultaneously determine the location and\n",
        "category of objects. In RPN, the features are from\n",
        "square (3×3) sliding windows and predict proposals\n",
        "relative to anchors with different scales and aspect\n",
        "ratios. Though both methods use sliding windows, the\n",
        "region proposal task is only the first stage of Faster RCNN—the downstream Fast R-CNN detector attends\n",
        "to the proposals to refine them. In the second stage of\n",
        "our cascade, the region-wise features are adaptively\n",
        "pooled [1], [2] from proposal boxes that more faithfully cover the features of the regions. We believe\n",
        "these features lead to more accurate detections."
      ],
      "metadata": {
        "id": "oWu1axDeA_3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What is RPN?**\n",
        "\n",
        "The Regional Proposal Network (RPN) is a specific type of fully convolutional network (FCN) and can be trained end-to-end specifically for the task for generating detection proposals. It is used by Fast R-CNN to simultaneously predicts object bounds and objectness scores at each position.\n",
        "\n",
        "The RPNs are designed to efficiently predict region proposals with a wide range of scales and aspect ratios. Compared to other methods such as Spatial pyramid pooling, Fast R-CNN, integrated regconition, etc. that use pyramid of images or filters, the proposed RPN introduce novel \"anchor\" boxes that serve as references at multiple scales and aspect ratios. And, it can avoids\n",
        "enumerating images or filters of multiple scales or\n",
        "aspect ratios.\n",
        "\n",
        "> (3.1. Region Proposal Networks) A Region Proposal Network (RPN) takes an image\n",
        "(of any size) as input and outputs a set of rectangular\n",
        "object proposals, each with an objectness score.3 We\n",
        "model this process with a fully convolutional network\n",
        "[7], which we describe in this section. Because our ultimate goal is to share computation with a Fast R-CNN\n",
        "object detection network [2], we assume that both nets\n",
        "share a common set of convolutional layers."
      ],
      "metadata": {
        "id": "U6EByFz38foR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is RoI pooling?**\n",
        "\n",
        "The Region of Interest (RoI) pooling is a layer in Fast R-CNN accepts the convolutional features and also the predicted bounding boxes as input and perform the max pooling on them to get a fixed-size feature map.\n",
        "\n",
        "> [1] K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling\n",
        "in deep convolutional networks for visual recognition,” in\n",
        "European Conference on Computer Vision (ECCV), 2014.\n",
        "> [2] R. Girshick, “Fast R-CNN,” in IEEE International Conference on\n",
        "Computer Vision (ICCV), 2015."
      ],
      "metadata": {
        "id": "y3ZveDfz-2N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the proper size for Anchor?**\n",
        "\n",
        "3 scales (128, 256, 512) and 3 ratios (1:1, 1:2, 2:1)<br>\n",
        "or<br>\n",
        "3 scales (128, 256, 512) and 1 ratio (1:1)\n",
        "\n",
        "These two settings achieved approximate equal mean Average Precision (mAP)"
      ],
      "metadata": {
        "id": "lfOt_P4yD4I7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What kind of data set is used and what kind of index value is obtained compared to the previous research?**\n",
        "\n",
        "The research used PASCAL VOC 2007, 2012, and MS COCO datasets.\n",
        "\n",
        "> (Abstract) For the very deep VGG-16 model [3],\n",
        "our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection\n",
        "accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image"
      ],
      "metadata": {
        "id": "kdKjJ--EHREY"
      }
    }
  ]
}