{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ9oEAn43Wnk"
      },
      "source": [
        "# **DIVE INTO CODE COURSE**\n",
        "## **Faster R-CNN and YOLO v3**\n",
        "**Student Name**: Doan Anh Tien<br>\n",
        "**Student ID**: 1852789<br>\n",
        "**Email**: tien.doan.g0pr0@hcmut.edu.vn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnoqrhrE7DBO"
      },
      "source": [
        "Run the implementation of Faster R-CNN [1].\n",
        "\n",
        "[1] Ren, S., He, K., Girshick, R., Sun, J .: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015 ) 91â€“99\n",
        "\n",
        "https://arxiv.org/pdf/1506.01497.pdf\n",
        "\n",
        "Please use the following. It is an implementation using Keras.\n",
        "\n",
        "duckrabbits / ObjectDetection at master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K4jtd8M7G6d"
      },
      "source": [
        "### **[Problem 1] Learning and Estimation**\n",
        "Please refer to the README to run the above implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is the script that I used with the terminal since using it in the notebook won't print out the messages.\n",
        "!python train.py -p annotation.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"run_faster_rcnn.png\" style=\"width: 60%;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python predict.py -i ./kaggle_simpson_testset -c ./save/train_20220126-205657_config.pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since my computer does not have CUDA and the required libraries, the predict part run very slow without the GPU-based iteration. However, I still able to make it run and the proof is provided as in the figure below.\n",
        "\n",
        "<img src=\"run_faster_rcnn2.png\" style=\"width: 60%;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>RPN classifier</th>\n",
              "      <th>RPN regression</th>\n",
              "      <th>Detector classifier</th>\n",
              "      <th>Detector regression</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.425</td>\n",
              "      <td>3.537379</td>\n",
              "      <td>0.195096</td>\n",
              "      <td>7.582271</td>\n",
              "      <td>4.093850</td>\n",
              "      <td>15.408596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.525</td>\n",
              "      <td>3.860771</td>\n",
              "      <td>0.293680</td>\n",
              "      <td>6.858210</td>\n",
              "      <td>1.822790</td>\n",
              "      <td>12.835451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.416993</td>\n",
              "      <td>0.116357</td>\n",
              "      <td>2.772097</td>\n",
              "      <td>0.790330</td>\n",
              "      <td>5.095777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.838187</td>\n",
              "      <td>0.182856</td>\n",
              "      <td>2.327368</td>\n",
              "      <td>0.644791</td>\n",
              "      <td>3.993202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.500</td>\n",
              "      <td>3.396416</td>\n",
              "      <td>0.152709</td>\n",
              "      <td>2.410058</td>\n",
              "      <td>0.738735</td>\n",
              "      <td>6.697919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.377696</td>\n",
              "      <td>0.140327</td>\n",
              "      <td>2.194178</td>\n",
              "      <td>0.595407</td>\n",
              "      <td>4.307608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.500</td>\n",
              "      <td>2.586178</td>\n",
              "      <td>0.096328</td>\n",
              "      <td>2.120901</td>\n",
              "      <td>0.505435</td>\n",
              "      <td>5.308843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.919045</td>\n",
              "      <td>0.117681</td>\n",
              "      <td>2.260537</td>\n",
              "      <td>0.536625</td>\n",
              "      <td>4.833888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.594891</td>\n",
              "      <td>0.133975</td>\n",
              "      <td>2.058122</td>\n",
              "      <td>0.378183</td>\n",
              "      <td>3.165171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.525</td>\n",
              "      <td>2.241241</td>\n",
              "      <td>0.084240</td>\n",
              "      <td>2.041632</td>\n",
              "      <td>0.528150</td>\n",
              "      <td>4.895264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  RPN classifier  RPN regression  Detector classifier  \\\n",
              "0     0.425        3.537379        0.195096             7.582271   \n",
              "1     0.525        3.860771        0.293680             6.858210   \n",
              "2     0.500        1.416993        0.116357             2.772097   \n",
              "3     0.500        0.838187        0.182856             2.327368   \n",
              "4     0.500        3.396416        0.152709             2.410058   \n",
              "5     0.500        1.377696        0.140327             2.194178   \n",
              "6     0.500        2.586178        0.096328             2.120901   \n",
              "7     0.500        1.919045        0.117681             2.260537   \n",
              "8     0.500        0.594891        0.133975             2.058122   \n",
              "9     0.525        2.241241        0.084240             2.041632   \n",
              "\n",
              "   Detector regression      Total  \n",
              "0             4.093850  15.408596  \n",
              "1             1.822790  12.835451  \n",
              "2             0.790330   5.095777  \n",
              "3             0.644791   3.993202  \n",
              "4             0.738735   6.697919  \n",
              "5             0.595407   4.307608  \n",
              "6             0.505435   5.308843  \n",
              "7             0.536625   4.833888  \n",
              "8             0.378183   3.165171  \n",
              "9             0.528150   4.895264  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The dataframe present the scores for each epoch\n",
        "score = pd.read_csv('out.csv', header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[Problem 2] Code reading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Where is the code that realizes the classifier?**\n",
        "\n",
        "The classifier is implemented in the <span style='color:cyan'>get_model</span> function of faster_rcnn.py (line 21), and in the <span style='color:cyan'>get_models</span> function of the predict.py (line 58).\n",
        "\n",
        "faster_rcnn.py (Line 21)\n",
        "```python\n",
        "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
        "```\n",
        "\n",
        "predict.py (Line 58)\n",
        "```python\n",
        "classifier = nn.classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(C.class_mapping), trainable=True)\n",
        "```\n",
        "\n",
        "The code that implement the model with classifier and loaded weights (start from Line 60)\n",
        "```python\n",
        "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.compile(optimizer='sgd', loss='mse')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Where is the anchor box drawing implemented?**\n",
        "\n",
        "The anchor is configured in the <span style='color:cyan'>detect_predict</span> function of the predict.py (Line 72)\n",
        "```python\n",
        "cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
        "cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Where is the code that realizes RPN?**\n",
        "\n",
        "The RPN is defined in the resnet.py file, and it is called in the faster_rcnn.py.\n",
        "\n",
        "resnet.py's definition (Line 196)\n",
        "```python\n",
        "def rpn(base_layers,num_anchors):\n",
        "\n",
        "    x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]\n",
        "```\n",
        "\n",
        "Function called in faster_rcnn.py (Line 18):\n",
        "```python\n",
        "rpn = nn.rpn(shared_layers, num_anchors)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Where is the code that implements RoI pooling?**\n",
        "\n",
        "The RoI pooling is implemented as a class in RoiPoolingConv.py, which is also used during the definition of the classifer of the Faster R-CNN model.\n",
        "\n",
        "RoiPoolingConv class (Line 7)\n",
        "```python\n",
        "class RoiPoolingConv(Layer):\n",
        "```\n",
        "\n",
        "RoI pooling being called (Line 209):\n",
        "```python\n",
        "out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[Problem 3] Estimation by learned weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output results\n",
        "\n",
        "<img src=\"yolo.png\" style=\"width: 60%;\">\n",
        "\n",
        "The keras model that has been saved after the process\n",
        "\n",
        "<img src=\"saved_model_yolo.png\" style=\"width: 30%;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python yolo_video.py --input Battefield4.mp4 --output Battefield4_yolo.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The link for the output is attached here. Since the size is so large, I upload it to YouTube for storing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python yolo_video.py --model model_data/yolo.h5 --classes model_data/coco_classes.txt --image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I choose a film picture that I took, it has a car and a pottedplant. Unfortunately, the model does not regconize the dar as it was covered by leaves (perhaps). But luckily it did regconize the pottedplant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The original picture\n",
        "\n",
        "<img src=\"car.jpg\" style=\"width: 30%;\">\n",
        "\n",
        "The detected picture\n",
        "\n",
        "<img src=\"yolo_car.png\" style=\"width: 30%;\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[Problem 4] Create a file for learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7889 6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>72</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>80</td>\n",
              "      <td>31</td>\n",
              "      <td>337</td>\n",
              "      <td>354</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>128</td>\n",
              "      <td>48</td>\n",
              "      <td>285</td>\n",
              "      <td>407</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>72</td>\n",
              "      <td>126</td>\n",
              "      <td>158</td>\n",
              "      <td>275</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>123</td>\n",
              "      <td>61</td>\n",
              "      <td>294</td>\n",
              "      <td>416</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0    1    2    3    4  \\\n",
              "0  simpsons_dataset/abraham_grampa_simpson/pic_00...   57   72   52   72   \n",
              "1  simpsons_dataset/abraham_grampa_simpson/pic_00...   80   31  337  354   \n",
              "2  simpsons_dataset/abraham_grampa_simpson/pic_00...  128   48  285  407   \n",
              "3  simpsons_dataset/abraham_grampa_simpson/pic_00...   72  126  158  275   \n",
              "4  simpsons_dataset/abraham_grampa_simpson/pic_00...  123   61  294  416   \n",
              "\n",
              "                        5  \n",
              "0  abraham_grampa_simpson  \n",
              "1  abraham_grampa_simpson  \n",
              "2  abraham_grampa_simpson  \n",
              "3  abraham_grampa_simpson  \n",
              "4  abraham_grampa_simpson  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "simpson = pd.read_csv('annotation.txt', header=None)\n",
        "n_feature, n_col = simpson.shape\n",
        "print(n_feature, n_col)\n",
        "simpson.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>80</td>\n",
              "      <td>31</td>\n",
              "      <td>337</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>128</td>\n",
              "      <td>48</td>\n",
              "      <td>285</td>\n",
              "      <td>407</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>72</td>\n",
              "      <td>126</td>\n",
              "      <td>158</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>123</td>\n",
              "      <td>61</td>\n",
              "      <td>294</td>\n",
              "      <td>416</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0    1    2    3    4  5\n",
              "0  simpsons_dataset/abraham_grampa_simpson/pic_00...   57   72   52   72  0\n",
              "1  simpsons_dataset/abraham_grampa_simpson/pic_00...   80   31  337  354  0\n",
              "2  simpsons_dataset/abraham_grampa_simpson/pic_00...  128   48  285  407  0\n",
              "3  simpsons_dataset/abraham_grampa_simpson/pic_00...   72  126  158  275  0\n",
              "4  simpsons_dataset/abraham_grampa_simpson/pic_00...  123   61  294  416  0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "classes = simpson[5].unique()\n",
        "simpson.iloc[:,5] = le.fit_transform(simpson.iloc[:,5])\n",
        "simpson.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = 'annotation.txt'\n",
        "anno_output = 'output/simpson_train.txt'\n",
        "classes_name = 'output/classes_name.txt'\n",
        "\n",
        "with open(input) as f:\n",
        "    lines = f.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        split_line = line.split(',')\n",
        "        img_path = split_line[0]\n",
        "        split_line[0] = '../../faster-rcnn/' + img_path\n",
        "        split_line[-1] = str(simpson.iloc[i,5]) + '\\n'\n",
        "\n",
        "        with open(anno_output, mode='a') as out_f:\n",
        "            join_line = ','.join(split_line)\n",
        "            join_line = join_line.replace('.jpg,', '.jpg ')\n",
        "            out_f.write(join_line)\n",
        "\n",
        "with open(classes_name, mode='a') as class_f:\n",
        "    for name in classes:\n",
        "        name +='\\n'\n",
        "        class_f.write(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[Problem 5] Confirmation that learning can be done**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After modify the train.py of YOLOv3, the train.py has been able to be executed and the learning can be performed. However, even with the CUDA installed and the GPU is used, the learning process still take significant long time to be finished, so I have put the terminal output in this cell below (up to the point of the below terminal's output, it has been 2 hours in my computer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(base) F:\\CODE\\DIVEINTOCODE\\diveintocode-ml\\Week6\\keras-yolo3-master\\keras-yolo3-master>python train.py\n",
        "2022-01-27 13:28:06.183136: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
        "2022-01-27 13:28:06.797939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4486 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:20:00.0, compute capability: 6.1\n",
        "Create YOLOv3 model with 9 anchors and 18 classes.\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_58 due to mismatch in shape ((1, 1, 1024, 69) vs (255, 1024, 1, 1)).\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_58 due to mismatch in shape ((69,) vs (255,)).\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_66 due to mismatch in shape ((1, 1, 512, 69) vs (255, 512, 1, 1)).\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_66 due to mismatch in shape ((69,) vs (255,)).\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_74 due to mismatch in shape ((1, 1, 256, 69) vs (255, 256, 1, 1)).\n",
        "WARNING:tensorflow:Skipping loading of weights for layer conv2d_74 due to mismatch in shape ((69,) vs (255,)).\n",
        "Load weights model_data/yolo_weights.h5.\n",
        "Freeze the first 249 layers of total 252 layers.\n",
        "2022-01-27 13:28:09.524593: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
        "2022-01-27 13:28:09.528251: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
        "2022-01-27 13:28:09.531430: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
        "2022-01-27 13:28:09.611018: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
        "2022-01-27 13:28:09.614811: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
        "C:\\Users\\Bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:367: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
        "  warnings.warn(\n",
        "Train on 7101 samples, val on 788 samples, with batch size 20.\n",
        "C:\\Users\\Bin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
        "  warnings.warn('Custom mask layers require a config and must override '\n",
        "Epoch 1/50\n",
        "2022-01-27 13:28:22.893145: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
        "  1/355 [..............................] - ETA: 1:21:57 - loss: 9223.09962022-01-27 13:28:27.171232: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
        "2022-01-27 13:28:27.175546: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
        "  2/355 [..............................] - ETA: 7:57 - loss: 8593.6660   2022-01-27 13:28:28.054954: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
        "2022-01-27 13:28:28.061347: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
        "2022-01-27 13:28:28.205979: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:526]  GpuTracer has collected 2913 callback api events and 2927 activity events.\n",
        "2022-01-27 13:28:28.322951: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
        "2022-01-27 13:28:28.501442: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\n",
        "\n",
        "2022-01-27 13:28:28.605392: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.trace.json.gz\n",
        "2022-01-27 13:28:28.789619: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\n",
        "\n",
        "2022-01-27 13:28:28.832345: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.memory_profile.json.gz\n",
        "2022-01-27 13:28:29.005446: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\n",
        "Dumped tool data for xplane.pb to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.xplane.pb\n",
        "Dumped tool data for overview_page.pb to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.overview_page.pb\n",
        "Dumped tool data for input_pipeline.pb to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.input_pipeline.pb\n",
        "Dumped tool data for tensorflow_stats.pb to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.tensorflow_stats.pb\n",
        "Dumped tool data for kernel_stats.pb to logs/000/train\\plugins\\profile\\2022_01_27_06_28_28\\BIN.kernel_stats.pb\n",
        "\n",
        "355/355 [==============================] - 912s 3s/step - loss: 337.8531 - val_loss: 43.3795\n",
        "Epoch 2/50\n",
        "355/355 [==============================] - 859s 2s/step - loss: 33.8784 - val_loss: 28.4187\n",
        "Epoch 3/50\n",
        "355/355 [==============================] - 928s 3s/step - loss: 25.9111 - val_loss: 24.2163\n",
        "Epoch 4/50\n",
        "355/355 [==============================] - 942s 3s/step - loss: 23.0570 - val_loss: 22.4284\n",
        "Epoch 5/50\n",
        "355/355 [==============================] - 909s 3s/step - loss: 21.6512 - val_loss: 21.3101\n",
        "Epoch 6/50\n",
        "355/355 [==============================] - 918s 3s/step - loss: 20.8120 - val_loss: 20.7309\n",
        "Epoch 7/50\n",
        "355/355 [==============================] - 1190s 3s/step - loss: 20.2807 - val_loss: 20.2473\n",
        "Epoch 8/50\n",
        "151/355 [===========>..................] - ETA: 8:40 - loss: 19.9065"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "treatise_reading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
