{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ9oEAn43Wnk"
      },
      "source": [
        "# **DIVE INTO CODE COURSE**\n",
        "## **Sprint Deep Learning - Convolution Neural Network**\n",
        "**Student Name**: Doan Anh Tien<br>\n",
        "**Student ID**: 1852789<br>\n",
        "**Email**: tien.doan.g0pr0@hcmut.edu.vn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJt2HavErNQs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import random\n",
        "from math import log2\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkkuRv7or0BF"
      },
      "source": [
        "### **[Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ung3u3oABWzg"
      },
      "source": [
        "class ConVo1D:\n",
        "  \n",
        "  def forward_propagate(self, x, w, b):\n",
        "    # Output value (which will converted to np.array)\n",
        "    a = []\n",
        "    for i in range(len(w)-1):\n",
        "      a.append(np.matmul(x[i:i+len(w)], w) + b[0])\n",
        "\n",
        "    return np.array(a)\n",
        "\n",
        "  def backward_propagate(self, x, w, da):\n",
        "    \"\"\"\n",
        "    The backward propagate intends to find three factors:\n",
        "    dw, db and dx\n",
        "\n",
        "    dw, db: \n",
        "      Using the formula similar to DNN model\n",
        "\n",
        "    dx:\n",
        "      Using the weight value multiply with the derivative of activate function da\n",
        "\n",
        "    \"\"\"\n",
        "    # Calculate db\n",
        "    db = np.sum(da)\n",
        "\n",
        "    # Calculate dw\n",
        "    dw = []\n",
        "    for i in range(len(w)):\n",
        "      dw.append(np.matmul(da, x[i:i+len(da)]))\n",
        "    dw = np.array(dw)\n",
        "\n",
        "    # Calculate dx\n",
        "    dx = []\n",
        "    # Adding all the shared errors\n",
        "    # The errors lies in the two heads of array (j - s < 0) and (j - s > N - 1)\n",
        "    new_w = np.insert(w[::-1], 0, 0) # Reverse the weight array\n",
        "    new_w = np.append(new_w, 0)\n",
        "    for i in range(len(new_w) - 1):\n",
        "      dx.append(np.matmul(da, new_w[i:i+len(da)]))\n",
        "    dx = np.array(dx[::-1]) # Reverse again\n",
        "\n",
        "    return dw, db, dx"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU8o99cc8PQA"
      },
      "source": [
        "### **[Problem 2] Output size calculation after one-dimensional convolution**\n",
        "The function will take in the size of input and perform the convolution operation, along with other parameters stride and padding, to get the size of output\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVofmIV98NnL"
      },
      "source": [
        "def output_size_calculation(n_in, F, P=0, S=1):\n",
        "  n_out = int((n_in + 2*P - F)/S + 1)\n",
        "  return n_out"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSMuMCTf-B2n"
      },
      "source": [
        "### **[Problem 3] Experiment of one-dimensional convolutional layer with small array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7TIq0pR-DE2"
      },
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "da = np.array([10, 20])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfV6_D1C-bEl",
        "outputId": "79ef84c0-ce96-48c9-dd74-7101fda3be39"
      },
      "source": [
        "C1D = ConVo1D()\n",
        "dw, db, dx = C1D.backward_propagate(x, w, da)\n",
        "\n",
        "print(\"Forward: \", C1D.forward_propagate(x, w, b))\n",
        "print(\"dw: \", dw)\n",
        "print(\"db: \", db)\n",
        "print(\"dx: \", dx)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward:  [35 50]\n",
            "dw:  [ 50  80 110]\n",
            "db:  30\n",
            "dx:  [ 30 110 170 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMB-iOh_UzA"
      },
      "source": [
        "### **[Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn3t1TzNJDRX"
      },
      "source": [
        "**Testing the numpy pad function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxl4OLprHPds",
        "outputId": "af554d8d-8bf6-4b16-fba2-8ef3c9b180a3"
      },
      "source": [
        "x = np.ones((3, 3))\n",
        "y = np.pad(x, pad_width=((0,0), (2,0)))\n",
        "y"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 1., 1.],\n",
              "       [0., 0., 1., 1., 1.],\n",
              "       [0., 0., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DD_Sor4_7UT"
      },
      "source": [
        "class ConVo1DFull:\n",
        "  \n",
        "  def __init__(self, filter_size, initializer, optimizer, channels_in = 1, channels_out = 1, pad=0):\n",
        "    self.filter_size = filter_size\n",
        "    self.optimizier = optimizer\n",
        "    self.channels_in = channels_in\n",
        "    self.channels_out = channels_out\n",
        "    self.n_out = None\n",
        "    self.pad = pad\n",
        "    self.W = initializer.W(channels_out, channels_in, filter_size)\n",
        "    self.B = initializer.B(channels_out)\n",
        "\n",
        "  def forward_propagate(self, X):\n",
        "    self.n_in = X.shape[-1]\n",
        "    self.n_out = output_size_calculation(self.n_in, self.filter_size, self.pad)\n",
        "\n",
        "    X = X.reshape(self.channels_in, self.n_in)\n",
        "    self.X = np.pad(X, ((0,0), ((self.filter_size-1), 0)))\n",
        "    self.X1 = np.zeros((self.channels_in, self.filter_size, self.n_in + (self.filter_size - 1)))\n",
        "\n",
        "    for i in range(self.filter_size):\n",
        "      self.X1[:, i] = np.roll(self.X, -i , axis=1)\n",
        "\n",
        "    A = np.sum(self.X1[:, :, self.filter_size -1 - self.pad:self.n_in + self.pad]*self.W[:, :, :, np.newaxis], axis=(1,2)) + self.B.reshape(-1, 1)\n",
        "\n",
        "    return A\n",
        "\n",
        "  def backward_propagate(self, dA):\n",
        "    \n",
        "    self.dW = np.sum(np.dot(dA, self.X1[:, :, self.filter_size - 1 - self.pad:self.n_in + self.pad, np.newaxis]), axis=-1)\n",
        "    self.dB = np.sum(dA, axis=1)\n",
        "    self.dA = np.pad(dA, ((0,0), (0, (self.filter_size - 1))))\n",
        "    self.dA1 = np.zeros((self.channels_out, self.filter_size, self.dA.shape[-1]))\n",
        "\n",
        "    for i in range(self.filter_size):\n",
        "      self.dA1[:, i] = np.roll(self.dA, i , axis=1)\n",
        "\n",
        "    dX = np.sum(np.matmul(self.W, self.dA1), axis=0)\n",
        "    self.optimizer.update(self)\n",
        "\n",
        "    return dX"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2qD4jTsiSG1"
      },
      "source": [
        "convo_test_model = ConVo1DFull(filter_size=3, initializer=WeightInitializer(0.01), optimizer=SGD(0.01), channels_in=2, channels_out=3, pad=0)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvT8yzVVi5jf"
      },
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
        "\n",
        "# Array shapes: (channels_in, channels_out, filter_size)\n",
        "convo_test_model.W = np.ones((3,2,3), dtype=float)\n",
        "convo_test_model.b = np.array([1,2,3], dtype=float)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwF1tc72khKe",
        "outputId": "5366953e-1864-493c-e466-3c3eabad643a"
      },
      "source": [
        "convo_test = convo_test_model.forward_propagate(x)\n",
        "print(\"Results of forward \\n\", convo_test)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of forward \n",
            " [[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGuTQz7X3dzU"
      },
      "source": [
        "### **[Problem 7] (Advance assignment) Arbitrary number of strides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYTNVCxI3gVz"
      },
      "source": [
        "class ConVo1DFullStride:\n",
        "  \n",
        "  def __init__(self, filter_size, initializer, optimizer, channels_in = 1, channels_out = 1, pad = 0, stride = 1):\n",
        "    self.filter_size = filter_size\n",
        "    self.optimizer = optimizer\n",
        "    self.channels_in = channels_in\n",
        "    self.channels_out = channels_out\n",
        "    self.n_out = None\n",
        "    self.pad = pad\n",
        "    self.stride = stride\n",
        "    self.W = initializer.W(channels_out, channels_in, filter_size)\n",
        "    self.B = initializer.b(channels_out)\n",
        "\n",
        "  def forward_propagate(self, X):\n",
        "    self.n_sample = X.shape[0]\n",
        "    self.n_in = X.shape[-1]\n",
        "    self.n_out = output_size_calculation(self.n_in, self.filter_size, self.pad, self.stride)\n",
        "\n",
        "    X = X.reshape(self.n_sample, self.channels_in, self.n_in)\n",
        "    self.X = np.pad(X, ((0,0), (0,0), ((self.filter_size-1), 0)))\n",
        "    self.X1 = np.zeros((self.n_sample, self.channels_in, self.filter_size, self.n_in + (self.filter_size - 1)))\n",
        "\n",
        "    for i in range(self.filter_size):\n",
        "      self.X1[:, :, i] = np.roll(self.X, -i , axis=1)\n",
        "\n",
        "    A = np.sum(self.X1[:, np.newaxis, :, :, self.filter_size -1 - self.pad:self.n_in + self.pad:self.stride]*self.W[:, :, :, np.newaxis], axis=(2,3)) + self.B.reshape(-1, 1)\n",
        "\n",
        "    return A\n",
        "\n",
        "  def backward_propagate(self, dA):\n",
        "    \n",
        "    self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.filter_size-1-self.pad:self.n_in+self.pad:self.stride], axis=(0,-1))\n",
        "    self.dB = np.sum(dA, axis=(0, -1))\n",
        "    self.dA = np.pad(dA, ((0,0), (0,0), (0, (self.filter_size - 1))))\n",
        "    self.dA1 = np.zeros((self.n_sample, self.channels_out, self.filter_size, self.dA.shape[-1]))\n",
        "\n",
        "    for i in range(self.filter_size):\n",
        "      self.dA1[:, :, i] = np.roll(self.dA, i , axis=-1)\n",
        "\n",
        "    dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1,3))\n",
        "    self.optimizer.update(self)\n",
        "\n",
        "    return dX"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAXZVYbJxM5M"
      },
      "source": [
        "### **[Problem 8] Learning and estimation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGSi5Umwt5F5"
      },
      "source": [
        "**Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODYZeFQ3t65C"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrzmqf26t932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de58b2d-8595-4d80-89c3-ab3dba5b0e19"
      },
      "source": [
        "print(X_train.shape) # (60000, 28, 28)\n",
        "print(y_train.shape) # (10000, 28, 28)\n",
        "print(X_test.shape) # (10000, 28, 28)\n",
        "print(y_test.shape)\n",
        "print(X_train[0].dtype) # uint8"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAFw2fEquDzK"
      },
      "source": [
        "**Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTnKI_5GuE1C"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR3PLEXruO64"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "o7Vfb9qTuOaf",
        "outputId": "fb02c2c4-dd27-45fc-f7a9-e44a20327f92"
      },
      "source": [
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "# X_train[index]: (784,)\n",
        "# image: (28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSAGU3J2utWE"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B06pBd4uu7l",
        "outputId": "21ab8869-2623-4c93-aed6-c0fd00d47583"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QCEvHdpvFUz",
        "outputId": "07558585-9077-4f01-fddf-ca3b5a5742e2"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(\"Original label: {}\".format(y_train.shape)) # (60000,)\n",
        "print(\"One hot train label: {}\".format(y_train_one_hot.shape)) # (60000, 10)\n",
        "print(\"One hot test label: {}\".format(y_test_one_hot.shape))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: (60000,)\n",
            "One hot train label: (60000, 10)\n",
            "One hot test label: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJeSWw_lvJD7",
        "outputId": "50c26cea-34c9-4e36-d0e0-83d94dd843e8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "print(\"Train data: \", X_train.shape)\n",
        "print(\"Validation data: \", X_val.shape)\n",
        "print(\"Train label: \", y_train.shape)\n",
        "print(\"Validation label: \", y_val.shape)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data:  (48000, 784)\n",
            "Validation data:  (12000, 784)\n",
            "Train label:  (48000, 10)\n",
            "Validation label:  (12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-93XH-ZZoS5"
      },
      "source": [
        "**Neural Network Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQUszf2Hhxju"
      },
      "source": [
        "\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]   \n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtO6mRA2hzbF"
      },
      "source": [
        "class XavierInitializer:\n",
        "    \"\"\"\n",
        "    Xavier Initializer\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1):\n",
        "        self.sigma = 1.0 / n_nodes1**(1/2)\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(n_nodes2)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzOayQJ2h5K2"
      },
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, *shape):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(*shape)\n",
        "\n",
        "    def b(self, *shape):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "\n",
        "        \"\"\"\n",
        "        return self.sigma * np.random.randn(*shape)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PVoNniMh8lP"
      },
      "source": [
        "class HeInitializer:\n",
        "    def __init__(self, n_nodes1):\n",
        "        self.sigma = (2.0 / n_nodes1)**(1/2)\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes2)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLqUqMeh-oe"
      },
      "source": [
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        return np.maximum(A, 0)\n",
        "    \n",
        "    def backward(self, dZ, Z):\n",
        "        return dZ * (Z > 0)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8rH3gHRiAcI"
      },
      "source": [
        "class Softmax:\n",
        "    def forward(self, A):\n",
        "        self.Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "        return self.Z\n",
        "    \n",
        "    def backward(self, y):\n",
        "        self.loss = self.loss_function(y)\n",
        "        return self.Z - y\n",
        "\n",
        "    def loss_function(self, Y, Z=None):\n",
        "        if Z is None:\n",
        "          Z = self.Z\n",
        "        # Adding 1e-7 for avoiding zero division\n",
        "        return (-1) * np.average(np.sum(Y * np.log(Z+1e-7), axis=1))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nn6tiShkCr_"
      },
      "source": [
        "class Tanh:\n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    return np.tanh(A)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    return dZ * (1 - (np.tanh(self.A))**2)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TTZGlHNkU2G"
      },
      "source": [
        "class Sigmoid:\n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    return self.sigmoid(A)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    _sig = self.sigmoid(self.A)\n",
        "    return dZ * (1 - _sig)*_sig\n",
        "\n",
        "  def sigmoid(self, X):\n",
        "    return 1 / (1 + np.exp(-X))"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84kOoI9LktYm"
      },
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "      self.lr = lr\n",
        "    \n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr * layer.dW\n",
        "      layer.B -= self.lr * layer.dB\n",
        "      return"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAd2r-u3lrE9"
      },
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "      self.lr = lr\n",
        "      self.HW = 1\n",
        "      self.HB = 1\n",
        "    \n",
        "    def update(self, layer):\n",
        "      self.HW -= layer.dW**2\n",
        "      self.HB -= layer.dB**2\n",
        "      layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "      layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "      return"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-n-C8-hqyW"
      },
      "source": [
        "class FullyC:\n",
        "    \"\"\"\n",
        "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2 : int\n",
        "      Number of nodes in the later layer\n",
        "    initializer: object\n",
        "      Instance of initialization method\n",
        "    optimizer: object\n",
        "      Instance of optimization method\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        # Initialize\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward Propagation\n",
        "\n",
        "        \"\"\"       \n",
        "        self.X = X\n",
        "        A = X @ self.W + self.B\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        Backward Propagation\n",
        "\n",
        "        \"\"\"\n",
        "        self.dA = dA\n",
        "        dZ = dA @ self.W.T\n",
        "        self.dW = self.X.T @ dA\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        # update\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611_SR4mrzVm"
      },
      "source": [
        "class Scratch1dCNNClassifier():\n",
        "    \"\"\"\n",
        "    Convolution neural network classifier with configurable structure\n",
        "    Parameters\n",
        "    ----------\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, num_epoch=10, lr=0.01, batch_size=20, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, verbose=True, activator=Tanh, optimizer=AdaGrad):\n",
        "      self.num_epoch = num_epoch\n",
        "      self.lr = lr\n",
        "      self.batch_size = batch_size\n",
        "      self.n_features = n_features\n",
        "      self.n_nodes1 = n_nodes1\n",
        "      self.n_nodes2 = n_nodes2\n",
        "      self.n_output = n_output\n",
        "      self.activator = activator\n",
        "      if activator == Sigmoid or activator == Tanh:\n",
        "        self.initializer = XavierInitializer(self.n_nodes1)\n",
        "      elif activator == ReLU:\n",
        "        self.initializer = HeInitializer(self.n_nodes1)\n",
        "\n",
        "      self.optimizer = optimizer\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "      self.val_enable = False\n",
        "      if X_val is not None:\n",
        "        self.val_enable = True\n",
        "\n",
        "      self.Conv1d_Strides = ConVo1DFullStride(filter_size=7, initializer=SimpleInitializer(0.01), optimizer=self.optimizer(self.lr), channels_in=1, channels_out=1, pad=3, stride=2)\n",
        "      self.Conv1d_Strides.n_out = output_size_calculation(X.shape[-1], self.Conv1d_Strides.filter_size, self.Conv1d_Strides.pad, self.Conv1d_Strides.stride)\n",
        "      self.activation1 = self.activator()\n",
        "      self.FC2 = FullyC(self.Conv1d_Strides.n_out, self.n_nodes2, self.initializer, self.optimizer(self.lr))\n",
        "      self.activation2 = self.activator()\n",
        "      self.FC3 = FullyC(self.n_nodes2, self.n_output, self.initializer, self.optimizer(self.lr))\n",
        "      self.activation3 = Softmax()\n",
        "\n",
        "      self.loss = []\n",
        "      self.loss_epoch = [self.activation3.loss_function(y, self.forward_propagation(X))]\n",
        "\n",
        "      for _ in range(self.num_epoch):\n",
        "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "        self.iter = len(get_mini_batch)\n",
        "        for mini_X, mini_y in get_mini_batch:\n",
        "          self.forward_propagation(mini_X)\n",
        "          self.backward_propagation(mini_X, mini_y)\n",
        "          self.loss.append(self.activation3.loss)\n",
        "        self.loss_epoch.append(self.activation3.loss_function(y, self.forward_propagation(X)))\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.forward_propagation(X), axis=1)\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        A1 = self.Conv1d_Strides.forward_propagate(X)\n",
        "        A1 = A1.reshape(A1.shape[0], A1.shape[-1])\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        return Z3\n",
        "\n",
        "    def backward_propagation(self, X, y_true):\n",
        "        dA3 = self.activation3.backward(y_true)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dA1 = dA1[:, np.newaxis]\n",
        "        dZ0 = self.Conv1d_Strides.backward_propagate(dA1)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMItJG5Wb4qH"
      },
      "source": [
        "**Model 1**\n",
        "\n",
        "Number of hidden layers: 3\n",
        "\n",
        "Layers size: [784, 400, 400, 10]\n",
        "\n",
        "Batch size: 20\n",
        "\n",
        "Learning rate: 0.01\n",
        "\n",
        "Number of epochs: 20\n",
        "\n",
        "Hidden layer estimator: Tanh\n",
        "\n",
        "Output layer estimator: Softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9WF0-AQsh0F",
        "outputId": "6cc697d8-75ce-4bf8-e5f6-abbe09936858"
      },
      "source": [
        "test = Scratch1dCNNClassifier(num_epoch=20, lr=0.01, batch_size=20, n_features=784, n_nodes1=400, n_nodes2=400, n_output=10, verbose=True)\n",
        "test.fit(X_train, y_train)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in sqrt\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnl8Xs9Yb33i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de451b3-4fb6-4f9d-81fc-1b9d217b47d6"
      },
      "source": [
        "y_pred = test.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.098"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    }
  ]
}